{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4e8ac3b9-d70c-4a71-a13c-0c761d8a4665"
    }
   },
   "source": [
    "# Taming Our Future AI Overlords\n",
    "\n",
    "Welcome! This is a workshop created for the [Lakeside Hackfest](https://www.lakeside-hackfest.com/) in 2018. Feel free to look around - but expect to learn things!\n",
    "\n",
    "The goal is to get an overview over the current status of machine learning techniques in a way that enables you to keep learning and understand what people are talking about, at least roughly. Therefore, this session covers:\n",
    "\n",
    "- Classic machine learning  \n",
    "- Deep learning with Keras and CNTK/Tensorflow\n",
    "- Cognitive Services \n",
    "\n",
    "In order to run this notebook, a Python 3.5 runtime environment is required, GPUs are of course preferred for more experimentation, but it should work with CPU only as well. With that available it's strictly necessary to have fun :) and simply work through everything from top to bottom. \n",
    "\n",
    "\n",
    "## Prepare\n",
    "\n",
    "The following cell (clumsily) installs all required dependencies using the current Python's `pip` installer. If you have a new-ish NVidia GPU available, be sure to install `cntk-gpu` (or `tensorflow-gpu`) instead of their regular CPU versions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "f3016fdb-e626-4c9d-badb-d14ef4027b42"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib scikit-learn numpy keras==2.2.2 azure-cognitiveservices-vision-customvision cntk-gpu==2.5.1 # cntk or cntk-gpu    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bb5283ac-ac7f-4982-af33-f06a944f1ad3"
    }
   },
   "source": [
    "## Classic Machine Learning\n",
    "\n",
    "The first step is to try out a simple classic machine learning algorithm and see how it performs. This will also establish a baseline for later models to beat! The most common thing to use here is `scikit-learn`, and the problem we are tackling is a multiclass-classification problem: we want to know what category that clothing item belongs to!\n",
    "\n",
    "### Task 1: >79% Accuracy\n",
    "\n",
    "To understand the process better, let's try and **train a model to be more than 79% accurate** - still, every 5th classificaiton will be wrong, but it should be good enough for now. Find an algorithm and parameters from [here](http://scikit-learn.org/stable/modules/multiclass.html) and train a model that exceeds 79% accuracy! Try out different things:\n",
    "\n",
    "- Algorithms\n",
    "- Parameters\n",
    "- Training data set size\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "468fa019-0a34-4ca8-be40-b0de3cb10a2a"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn import neighbors, linear_model, tree, ensemble, neural_network, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "e02c22a3-f96c-4b1c-9fc8-ff04afeecd6e"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = np.genfromtxt(path, delimiter=',')[1:] # skip header row\n",
    "    y, x = np.split(data, [1], axis = 1) # split vertically after the first column, which contains the class\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "2d40da66-9ddc-4bc2-8979-0a47ef45fb4d"
    }
   },
   "outputs": [],
   "source": [
    "def print_prediction_stats(label, y_pred, y_true):\n",
    "    print(label, accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "eb61b3a9-cea2-4214-8764-5f83c9fa2467"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "9398ad78-a0e9-40a7-9541-a25d08bf72ed"
    }
   },
   "outputs": [],
   "source": [
    "def explore(X, y):\n",
    "\n",
    "    random_img = random.choice(X);\n",
    "    plt.figure()\n",
    "    plt.title(\"The Random Image\")\n",
    "    plt.imshow(random_img.reshape((28,28)), cmap = 'gray')\n",
    "   \n",
    "    plt.figure(figsize = (16, 6))\n",
    "    plt.title(\"Random Image Histogram\")\n",
    "    c = Counter()\n",
    "    for r in random_img: c[r] += 1\n",
    "    colors = list(range(0, 256))\n",
    "    plt.hist([c[h] for h in colors], colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "b1c513fb-9e2b-4aa5-bb9a-2e79ab1f21c0"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(\"fashion-mnist_train.csv\")\n",
    "X_test, y_test = load_data(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "3f3bf255-c20c-4aa5-9363-e5ca2a57b7e4"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_mnist(n_training = 5000):\n",
    "    explore(X_train, y_train)\n",
    "    X, _, y, _ = train_test_split(X_train, y_train, train_size=n_training, test_size=0)\n",
    "    def f(model):\n",
    "        trained = train(model, X, y)\n",
    "        y_pred = trained.predict(X_test)\n",
    "        print_prediction_stats(trained, y_test, y_pred)\n",
    "        return trained\n",
    "    return f\n",
    "\n",
    "MNIST = create_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "a833377f-9eea-4ad1-942c-8f2c68f712e6"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform') 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) 0.7483\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) 0.7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) 0.8295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Task 1: Run MNIST(MyModelInstance)\n",
    "#\n",
    "\n",
    "MNIST(neighbors.KNeighborsClassifier(1))\n",
    "MNIST(linear_model.LogisticRegression())\n",
    "MNIST(tree.DecisionTreeClassifier())\n",
    "MNIST(ensemble.RandomForestClassifier())\n",
    "MNIST(neural_network.MLPClassifier())\n",
    "MNIST(svm.SVC(kernel=\"poly\", C=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c3aaa5cf-e86d-4ff2-86fa-54b8876620cb"
    }
   },
   "source": [
    "## Deep Learning\n",
    "\n",
    "In this second part we are going to utilize deep learning strategies in order to improve accuracy! In particular, the neural network we will use is a convolutional neural network with 18 layers, taken from the brilliant [deep Learning turkey](https://medium.com/deep-learning-turkey/deep-learning-lab-episode-1-fashion-mnist-c7af60029836). Instead of training from scratch (because who has that kind of time), we are going to use pre-learned weights to get a network that already performs very well. \n",
    "\n",
    "In fact, this is a very common strategy: taking existing network architectures ([AlexNet](https://en.wikipedia.org/wiki/AlexNet), VGGNet, LeNet, ...) and training on top of pre-trained weights (e.g. [ImageNet data](http://www.image-net.org/)). This process is also called transfer learning and is quite useful for getting good results quickly. \n",
    "\n",
    "Instead of the turkey's network we could have adjusted the image size (filling up the background) to conform to AlexNet's (or similar) dimensions of 224x224. This is something that you can try on your own.\n",
    "\n",
    "\n",
    "\n",
    "### Task 2: Keep Training\n",
    "\n",
    "Once a network has been created, it's possible to add weights from previous training runs giving it a head start. Use Keras to load weights into the model and train for another epoch or two (depending on the time).  \n",
    "\n",
    "### Task 3: Gather Stats\n",
    "\n",
    "With the deep learning model, predict the classes of a few images from the test set and see how it performs. To do that, collect classification errors relative to the sample size!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"cntk\" # delete this line to use tensorflow\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "79ae206c-eeee-4ca8-b9f5-9382b46adf9d"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 676,842\n",
      "Trainable params: 676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.01), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (5, 5), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (5, 5), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "cdd73dd5-bb37-442f-992c-abb6cf81dfa1"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.2955 - acc: 0.9150 - val_loss: 0.2439 - val_acc: 0.9356\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.2938 - acc: 0.9147 - val_loss: 0.2315 - val_acc: 0.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3d97579b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Task 2: Keep training by loading the weights and running another training epoch or two.\n",
    "#\n",
    "\n",
    "model.load_weights(\"fashion-mnist-90.h5\")\n",
    "epochs = 2                # loss function value will be stabilized after 93rd epoch\n",
    "batch_size = 128           # or 32, 64 ... \n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "34e21520-93ff-4b77-9a54-ba864287a5d6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Task 3: Gather prediction accuracy for a few (10?) items from the test data set\n",
    "#\n",
    "\n",
    "test_data = list(zip(x_test, y_test))\n",
    "\n",
    "# Generate a random test set\n",
    "\n",
    "sample_size = 20\n",
    "error = 0\n",
    "\n",
    "x, y = tuple(zip(*(random.choice(test_data) for _ in range(0, sample_size))))\n",
    "result = model.predict_classes(np.array(x))\n",
    "for predicted, actual in zip(result, [np.where(y_ == 1)[0][0] for y_ in y]):\n",
    "    if predicted != actual: error += 1\n",
    "\n",
    "print(\"Test accuracy: \", 1 - (error / sample_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d44bf531-0b4e-47dd-9d69-bcf1e4bedff6"
    }
   },
   "source": [
    "## APIs\n",
    "\n",
    "In a last attempt, let's try out some prebuilt services. In many cases they are a lot easier to use and produce usable results within minutes, making them ideal for prototypes as well as production cases. \n",
    "\n",
    "Microsoft's cognitive services contain various services around custom and prebuilt machine learning tasks, paid per call with a free tier. For this exercise, the free tier should work out fine - however production use cases better use a paid version :)\n",
    "\n",
    "The service we are using here is called [custom vision](https://customvision.ai) and provides a trainable image classification service complete with: \n",
    "\n",
    "- Model versioning\n",
    "- Rest API\n",
    "- UI for labelling and data management\n",
    "\n",
    "\n",
    "### Task 4: Data Wrangling\n",
    "\n",
    "A major task in any machine learning engagement is to get the data you need in the shape, mode, and size required. With this task you should fill in the function `make_img()` which is expected to create an image from a simple array of values. This image should be usable for the API!\n",
    "\n",
    "### Task 5: Test The API's Model\n",
    "\n",
    "Once trained, the model can deliver predictions! Find out how, implement it, and see how well it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping class numbers to names\n",
    "\n",
    "mapping = {\n",
    "    0: \"T-shirt/top\", \n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "training_key = \"\"\n",
    "project_id = \"\"\n",
    "prediction_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "638eaa8b-123c-47cb-8355-b0bc91a1c29e"
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "from azure.cognitiveservices.vision.customvision.prediction import prediction_endpoint\n",
    "from azure.cognitiveservices.vision.customvision.prediction.prediction_endpoint import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbpresent": {
     "id": "045640f1-1f1c-4172-af34-c3becd59f797"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Task 4: Create a JPEG, PNG, or BMP to upload to custom vision.\n",
    "# \n",
    "\n",
    "def make_img(pd):\n",
    "    img = np.array(pd).reshape((28, 28))\n",
    "    img_data = BytesIO()\n",
    "    plt.imsave(img_data, img, format=\"png\", cmap=plt.cm.gray)\n",
    "    img_data.seek(0) # Reset byte stream\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "fba30b74-8b64-49ec-b99e-e960da1197dd"
    }
   },
   "outputs": [],
   "source": [
    "# Create API connection\n",
    "trainer = training_api.TrainingApi(training_key)\n",
    "\n",
    "# Creating tags twice will result in an error...\n",
    "tags = [trainer.create_tag(project_id, name) for key, name in sorted(mapping.items(), key=lambda i: i[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "b77915c7-41e7-4c78-b697-8bd5dfe185ad"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a test set suitable for the free tier (5000 images take a long time to upload...)\n",
    "\n",
    "X, _, Y, _ = train_test_split(X_train, y_train, train_size = 5000, test_size=0)\n",
    "\n",
    "for x, y in zip(X, Y):\n",
    "    img_data = make_img(x)\n",
    "    status = trainer.create_images_from_data(project_id, img_data, [ tags[np.where(y == 1)[0][0]].id ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbpresent": {
     "id": "307b9486-4e7e-408c-9c0a-1c5b489078f1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Completed\n"
     ]
    }
   ],
   "source": [
    "# Start training and wait for it to finish.\n",
    "\n",
    "iteration = trainer.train_project(project_id)\n",
    "\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project_id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "b46874dc-71e8-458a-9db6-a7d68bb6b4c7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Task 5: Predict! Check the tutorials for how to create a prediction endpoint and use it to send images there\n",
    "#\n",
    "from functools import reduce\n",
    "test_data = list(zip(X_test, y_test))\n",
    "\n",
    "# Generate a random test set\n",
    "\n",
    "sample_size = 20\n",
    "\n",
    "sample = [random.choice(test_data) for _ in range(0, sample_size)]\n",
    "\n",
    "predictor = prediction_endpoint.PredictionEndpoint(prediction_key)\n",
    "\n",
    "# Feed test data into the API\n",
    "\n",
    "errors = 0\n",
    "\n",
    "for x, y in sample: \n",
    "    img_data = make_img(x)\n",
    "    results = predictor.predict_image(project_id, img_data, iteration.id)\n",
    "    actual = mapping[np.where(y == 1)[0][0]]\n",
    "    probability, tag = reduce(lambda p, c: p if p[0] > c.probability else (c.probability, c.tag_name), results.predictions, (-1, \"Invalid\"))\n",
    "    if actual != tag: errors += 1\n",
    "        \n",
    "print(\"Test accuracy: \", 1 - (errors / sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!\n",
    "\n",
    "That's it, there is way more to learn out there and this session should provide an overview over what's possible and a basic vocabulary. Check out these links to find out more about this entire space!\n",
    "\n",
    "- [Andrew Ng's ML basics course](https://www.coursera.org/learn/machine-learning)\n",
    "- [Deep Learning specialization](https://www.coursera.org/specializations/deep-learning)\n",
    "- [Understanding CNNs](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "- [Custom Vision SDK Tutorial](https://docs.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/python-tutorial)\n",
    "- [Keras Docs](https://keras.io/)\n",
    "- [Kaggle](https://kaggle.com)\n",
    "- [Deep Learning the Fashion MNIST](https://medium.com/deep-learning-turkey/deep-learning-lab-episode-1-fashion-mnist-c7af60029836)\n",
    "- [Fashion MNIST Benchmarks](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#)\n",
    "- [CNTK Tutorials](https://cntk.ai/pythondocs/tutorials.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nbpresent": {
   "slides": {
    "0be37d33-b574-47f1-ba45-b13e88060351": {
     "id": "0be37d33-b574-47f1-ba45-b13e88060351",
     "prev": "acb069fb-3766-49ea-979f-6a7212d54b65",
     "regions": {
      "28e2b5c7-1f90-49ed-aa8c-a17c3ee77dd7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b77915c7-41e7-4c78-b697-8bd5dfe185ad",
        "part": "whole"
       },
       "id": "28e2b5c7-1f90-49ed-aa8c-a17c3ee77dd7"
      }
     }
    },
    "2365376d-cb66-4107-9f84-f21be017a4f3": {
     "id": "2365376d-cb66-4107-9f84-f21be017a4f3",
     "prev": "92ab60e1-65aa-4b5c-b051-39c105afe277",
     "regions": {
      "e14027fd-c077-4010-8d05-81ae45f911e2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b1c513fb-9e2b-4aa5-bb9a-2e79ab1f21c0",
        "part": "whole"
       },
       "id": "e14027fd-c077-4010-8d05-81ae45f911e2"
      }
     }
    },
    "2aa1ae0d-4176-4312-a159-3763caa82fbb": {
     "id": "2aa1ae0d-4176-4312-a159-3763caa82fbb",
     "prev": "fcabb04c-b487-4927-96c3-d48cbba2aa6a",
     "regions": {
      "a19c3721-42b4-4779-9b79-7212da0a0d57": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bb5283ac-ac7f-4982-af33-f06a944f1ad3",
        "part": "whole"
       },
       "id": "a19c3721-42b4-4779-9b79-7212da0a0d57"
      }
     }
    },
    "2c1289f7-ca30-4051-85f3-4c9f28c8cdc3": {
     "id": "2c1289f7-ca30-4051-85f3-4c9f28c8cdc3",
     "prev": "96580448-4db1-47a0-838d-4c16f61f288f",
     "regions": {
      "b574a93a-18a8-4a94-9058-6091b9afc9cd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3016fdb-e626-4c9d-badb-d14ef4027b42",
        "part": "whole"
       },
       "id": "b574a93a-18a8-4a94-9058-6091b9afc9cd"
      }
     }
    },
    "2f10d723-9a11-4539-8c04-9991772075f0": {
     "id": "2f10d723-9a11-4539-8c04-9991772075f0",
     "prev": "5c8fa775-66c0-4cba-b249-3874a5f47569",
     "regions": {
      "c6d2d156-3f12-4068-970e-c9dbe7a386a3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4fa0d0fb-566d-464a-8774-b1b36131f57e",
        "part": "whole"
       },
       "id": "c6d2d156-3f12-4068-970e-c9dbe7a386a3"
      }
     }
    },
    "5815c285-ab3f-4406-b93b-a583295c3d61": {
     "id": "5815c285-ab3f-4406-b93b-a583295c3d61",
     "prev": "bce54b2a-6256-4069-9624-f11a4bd12335",
     "regions": {
      "38188b22-a7bb-4308-bebb-56bca6d14381": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e02c22a3-f96c-4b1c-9fc8-ff04afeecd6e",
        "part": "whole"
       },
       "id": "38188b22-a7bb-4308-bebb-56bca6d14381"
      }
     }
    },
    "5c8fa775-66c0-4cba-b249-3874a5f47569": {
     "id": "5c8fa775-66c0-4cba-b249-3874a5f47569",
     "prev": "0be37d33-b574-47f1-ba45-b13e88060351",
     "regions": {
      "85fdb49e-140f-434b-9070-7d454f5300c7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "307b9486-4e7e-408c-9c0a-1c5b489078f1",
        "part": "whole"
       },
       "id": "85fdb49e-140f-434b-9070-7d454f5300c7"
      }
     }
    },
    "69061ed9-760b-43d8-9157-4443c1668b95": {
     "id": "69061ed9-760b-43d8-9157-4443c1668b95",
     "prev": "cb9103ba-165d-417e-9aaa-59620676f5bd",
     "regions": {
      "0fd7695f-7584-4399-acea-3ed8e3d6d674": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "045640f1-1f1c-4172-af34-c3becd59f797",
        "part": "whole"
       },
       "id": "0fd7695f-7584-4399-acea-3ed8e3d6d674"
      }
     }
    },
    "6db60f0b-1781-4711-99c6-befded93468c": {
     "id": "6db60f0b-1781-4711-99c6-befded93468c",
     "prev": "ea42c287-0300-4496-bc78-b1b44054e1c8",
     "regions": {
      "3a53efeb-b6ba-4840-a324-b04fc647f109": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a833377f-9eea-4ad1-942c-8f2c68f712e6",
        "part": "whole"
       },
       "id": "3a53efeb-b6ba-4840-a324-b04fc647f109"
      }
     }
    },
    "716699f0-37c4-4539-8345-0ff2687ac905": {
     "id": "716699f0-37c4-4539-8345-0ff2687ac905",
     "prev": "2f10d723-9a11-4539-8c04-9991772075f0",
     "regions": {
      "ea3d38f2-3d2f-4e3b-8c7d-904339fe67de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6cc3c11e-b663-4e82-ada8-1b6bd8991a26",
        "part": "whole"
       },
       "id": "ea3d38f2-3d2f-4e3b-8c7d-904339fe67de"
      }
     }
    },
    "7c4392d6-f195-4893-9f22-551e2d16cfd3": {
     "id": "7c4392d6-f195-4893-9f22-551e2d16cfd3",
     "prev": "b3c712ae-6eb6-47aa-bef6-8c18861f0d2f",
     "regions": {
      "c9ca8c1e-198c-46c9-93a8-1b5e91cbdd72": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "79ae206c-eeee-4ca8-b9f5-9382b46adf9d",
        "part": "whole"
       },
       "id": "c9ca8c1e-198c-46c9-93a8-1b5e91cbdd72"
      }
     }
    },
    "7cb9a248-cf6e-47e8-8f2a-2a84a4637663": {
     "id": "7cb9a248-cf6e-47e8-8f2a-2a84a4637663",
     "prev": "5815c285-ab3f-4406-b93b-a583295c3d61",
     "regions": {
      "f014594a-dfdf-47f1-8029-92bc88a352ce": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2d40da66-9ddc-4bc2-8979-0a47ef45fb4d",
        "part": "whole"
       },
       "id": "f014594a-dfdf-47f1-8029-92bc88a352ce"
      }
     }
    },
    "80a6e1cf-4dfd-4758-800e-481e217f4294": {
     "id": "80a6e1cf-4dfd-4758-800e-481e217f4294",
     "prev": "7cb9a248-cf6e-47e8-8f2a-2a84a4637663",
     "regions": {
      "43a13f25-727f-4c46-a317-16db439c2892": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "eb61b3a9-cea2-4214-8764-5f83c9fa2467",
        "part": "whole"
       },
       "id": "43a13f25-727f-4c46-a317-16db439c2892"
      }
     }
    },
    "92ab60e1-65aa-4b5c-b051-39c105afe277": {
     "id": "92ab60e1-65aa-4b5c-b051-39c105afe277",
     "prev": "80a6e1cf-4dfd-4758-800e-481e217f4294",
     "regions": {
      "d56ec6a8-2dda-4206-bb44-a299050b6470": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9398ad78-a0e9-40a7-9541-a25d08bf72ed",
        "part": "whole"
       },
       "id": "d56ec6a8-2dda-4206-bb44-a299050b6470"
      }
     }
    },
    "96580448-4db1-47a0-838d-4c16f61f288f": {
     "id": "96580448-4db1-47a0-838d-4c16f61f288f",
     "prev": null,
     "regions": {
      "c4d2f23d-eed8-4ab7-ac77-ff32ef495f08": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e8ac3b9-d70c-4a71-a13c-0c761d8a4665",
        "part": "whole"
       },
       "id": "c4d2f23d-eed8-4ab7-ac77-ff32ef495f08"
      }
     }
    },
    "97c3dd3d-aaaf-4ae7-a3b5-6fc8e18d4cc4": {
     "id": "97c3dd3d-aaaf-4ae7-a3b5-6fc8e18d4cc4",
     "prev": "afdd204b-5dae-4d28-9e0b-c49c561c113b",
     "regions": {
      "6634d276-7f56-4e6c-bb6d-708dc185ba55": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fba30b74-8b64-49ec-b99e-e960da1197dd",
        "part": "whole"
       },
       "id": "6634d276-7f56-4e6c-bb6d-708dc185ba55"
      }
     }
    },
    "acb069fb-3766-49ea-979f-6a7212d54b65": {
     "id": "acb069fb-3766-49ea-979f-6a7212d54b65",
     "prev": "97c3dd3d-aaaf-4ae7-a3b5-6fc8e18d4cc4",
     "regions": {
      "2720cb18-ad75-4d31-b66d-1a25e6701360": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bfb47c20-60c0-49a0-99ed-af3739ca8762",
        "part": "whole"
       },
       "id": "2720cb18-ad75-4d31-b66d-1a25e6701360"
      }
     }
    },
    "afdd204b-5dae-4d28-9e0b-c49c561c113b": {
     "id": "afdd204b-5dae-4d28-9e0b-c49c561c113b",
     "prev": "69061ed9-760b-43d8-9157-4443c1668b95",
     "regions": {
      "e0ac2320-3076-4d3a-95df-65f8ae908c44": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3ae6cda9-5815-4cc2-b269-4c3541e356d6",
        "part": "whole"
       },
       "id": "e0ac2320-3076-4d3a-95df-65f8ae908c44"
      }
     }
    },
    "b3c712ae-6eb6-47aa-bef6-8c18861f0d2f": {
     "id": "b3c712ae-6eb6-47aa-bef6-8c18861f0d2f",
     "prev": "6db60f0b-1781-4711-99c6-befded93468c",
     "regions": {
      "e8e140ae-eda7-4a78-93ea-f8b121238c20": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c3aaa5cf-e86d-4ff2-86fa-54b8876620cb",
        "part": "whole"
       },
       "id": "e8e140ae-eda7-4a78-93ea-f8b121238c20"
      }
     }
    },
    "bce54b2a-6256-4069-9624-f11a4bd12335": {
     "id": "bce54b2a-6256-4069-9624-f11a4bd12335",
     "prev": "2aa1ae0d-4176-4312-a159-3763caa82fbb",
     "regions": {
      "758f5525-5ed3-4226-b9c2-466f094c4879": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "468fa019-0a34-4ca8-be40-b0de3cb10a2a",
        "part": "whole"
       },
       "id": "758f5525-5ed3-4226-b9c2-466f094c4879"
      }
     }
    },
    "cb9103ba-165d-417e-9aaa-59620676f5bd": {
     "id": "cb9103ba-165d-417e-9aaa-59620676f5bd",
     "prev": "f24d2b59-6376-4de6-8bbd-cee9dfa8ab41",
     "regions": {
      "66bd2fa3-2fb8-4db5-9e9b-a38fc29823e3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "638eaa8b-123c-47cb-8355-b0bc91a1c29e",
        "part": "whole"
       },
       "id": "66bd2fa3-2fb8-4db5-9e9b-a38fc29823e3"
      }
     }
    },
    "ccd11861-c269-4b59-86f4-5ce8b69a82df": {
     "id": "ccd11861-c269-4b59-86f4-5ce8b69a82df",
     "prev": "7c4392d6-f195-4893-9f22-551e2d16cfd3",
     "regions": {
      "a6262b5e-3e62-4fe4-84ef-39818f046dc1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cdd73dd5-bb37-442f-992c-abb6cf81dfa1",
        "part": "whole"
       },
       "id": "a6262b5e-3e62-4fe4-84ef-39818f046dc1"
      }
     }
    },
    "dad4a1a8-b156-4028-8084-323625610b24": {
     "id": "dad4a1a8-b156-4028-8084-323625610b24",
     "prev": "716699f0-37c4-4539-8345-0ff2687ac905",
     "regions": {
      "fb5782fa-8d30-490e-b0b0-431f1a2dc6ab": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b46874dc-71e8-458a-9db6-a7d68bb6b4c7",
        "part": "whole"
       },
       "id": "fb5782fa-8d30-490e-b0b0-431f1a2dc6ab"
      }
     }
    },
    "dc453b61-29d1-4430-82a5-0342d3d3ce1d": {
     "id": "dc453b61-29d1-4430-82a5-0342d3d3ce1d",
     "prev": "dad4a1a8-b156-4028-8084-323625610b24",
     "regions": {
      "57d2bc68-ef49-4e3e-95f9-b70cbba6232a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2dd0f0a2-5224-4975-a5a8-82ba5430fa79",
        "part": "whole"
       },
       "id": "57d2bc68-ef49-4e3e-95f9-b70cbba6232a"
      }
     }
    },
    "ea42c287-0300-4496-bc78-b1b44054e1c8": {
     "id": "ea42c287-0300-4496-bc78-b1b44054e1c8",
     "prev": "2365376d-cb66-4107-9f84-f21be017a4f3",
     "regions": {
      "3bb78ab5-47f7-4c08-a864-c7365a3f2271": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3f3bf255-c20c-4aa5-9363-e5ca2a57b7e4",
        "part": "whole"
       },
       "id": "3bb78ab5-47f7-4c08-a864-c7365a3f2271"
      }
     }
    },
    "f24d2b59-6376-4de6-8bbd-cee9dfa8ab41": {
     "id": "f24d2b59-6376-4de6-8bbd-cee9dfa8ab41",
     "prev": "f3be65ae-68cd-497e-962d-2e134190dbaf",
     "regions": {
      "3924f060-84f7-4569-adda-ca9a7166e21d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d44bf531-0b4e-47dd-9d69-bcf1e4bedff6",
        "part": "whole"
       },
       "id": "3924f060-84f7-4569-adda-ca9a7166e21d"
      }
     }
    },
    "f3be65ae-68cd-497e-962d-2e134190dbaf": {
     "id": "f3be65ae-68cd-497e-962d-2e134190dbaf",
     "prev": "ccd11861-c269-4b59-86f4-5ce8b69a82df",
     "regions": {
      "3d5e76f4-0769-4365-a79a-d70685f1dbd8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "34e21520-93ff-4b77-9a54-ba864287a5d6",
        "part": "whole"
       },
       "id": "3d5e76f4-0769-4365-a79a-d70685f1dbd8"
      }
     }
    },
    "fcabb04c-b487-4927-96c3-d48cbba2aa6a": {
     "id": "fcabb04c-b487-4927-96c3-d48cbba2aa6a",
     "prev": "2c1289f7-ca30-4051-85f3-4c9f28c8cdc3",
     "regions": {
      "14f7c226-cac9-48bf-a269-207e4b9d479f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "444f1646-a6c9-4527-955b-185347192e5c",
        "part": "whole"
       },
       "id": "14f7c226-cac9-48bf-a269-207e4b9d479f"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
