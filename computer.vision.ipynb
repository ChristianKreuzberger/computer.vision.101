{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4e8ac3b9-d70c-4a71-a13c-0c761d8a4665"
    }
   },
   "source": [
    "# Taming Our Future AI Overlords\n",
    "\n",
    "Welcome! This is a workshop created for the [Lakeside Hackfest](https://www.lakeside-hackfest.com/) in 2018. Feel free to look around - but expect to learn things!\n",
    "\n",
    "The goal is to get an overview over the current status of machine learning techniques in a way that enables you to keep learning and understand what people are talking about, at least roughly. Therefore, this session covers:\n",
    "\n",
    "- Classic machine learning  \n",
    "- Deep learning with Keras and CNTK/Tensorflow\n",
    "- Cognitive Services \n",
    "\n",
    "In order to run this notebook, a Python 3.5 runtime environment is required, GPUs are of course preferred for more experimentation, but it should work with CPU only as well. With that available it's strictly necessary to have fun :) and simply work through everything from top to bottom. \n",
    "\n",
    "\n",
    "## Prepare\n",
    "\n",
    "The following cell (clumsily) installs all required dependencies using the current Python's `pip` installer. If you have a new-ish NVidia GPU available, be sure to install `cntk-gpu` (or `tensorflow-gpu`) instead of their regular CPU versions. Check the `requirements.txt` file to find out more about the dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f3016fdb-e626-4c9d-badb-d14ef4027b42"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bb5283ac-ac7f-4982-af33-f06a944f1ad3"
    }
   },
   "source": [
    "## Classic Machine Learning\n",
    "\n",
    "The first step is to try out a simple classic machine learning algorithm and see how it performs. This will also establish a baseline for later models to beat! The most common thing to use here is `scikit-learn`, and the problem we are tackling is a multiclass-classification problem: we want to know what category that clothing item belongs to!\n",
    "\n",
    "### Task 1: >79% Accuracy\n",
    "\n",
    "To understand the process better, let's try and **train a model to be more than 79% accurate** - still, every 5th classificaiton will be wrong, but it should be good enough for now. Find an algorithm and parameters from [here](http://scikit-learn.org/stable/modules/multiclass.html) and train a model that exceeds 79% accuracy! Try out different things:\n",
    "\n",
    "- Algorithms\n",
    "- Parameters\n",
    "- Training data set size\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "468fa019-0a34-4ca8-be40-b0de3cb10a2a"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn import neighbors, linear_model, tree, ensemble, neural_network, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e02c22a3-f96c-4b1c-9fc8-ff04afeecd6e"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = np.genfromtxt(path, delimiter=',')[1:] # skip header row\n",
    "    y, x = np.split(data, [1], axis = 1) # split vertically after the first column, which contains the class\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2d40da66-9ddc-4bc2-8979-0a47ef45fb4d"
    }
   },
   "outputs": [],
   "source": [
    "def print_prediction_stats(label, y_pred, y_true):\n",
    "    print(label, accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "eb61b3a9-cea2-4214-8764-5f83c9fa2467"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9398ad78-a0e9-40a7-9541-a25d08bf72ed"
    }
   },
   "outputs": [],
   "source": [
    "def explore(X, y):\n",
    "\n",
    "    random_img = random.choice(X);\n",
    "    plt.figure()\n",
    "    plt.title(\"The Random Image\")\n",
    "    plt.imshow(random_img.reshape((28,28)), cmap = 'gray')\n",
    "   \n",
    "    plt.figure(figsize = (16, 6))\n",
    "    plt.title(\"Random Image Histogram\")\n",
    "    c = Counter()\n",
    "    for r in random_img: c[r] += 1\n",
    "    colors = list(range(0, 256))\n",
    "    plt.hist([c[h] for h in colors], colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b1c513fb-9e2b-4aa5-bb9a-2e79ab1f21c0"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(\"fashion-mnist_train.csv\")\n",
    "X_test, y_test = load_data(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3f3bf255-c20c-4aa5-9363-e5ca2a57b7e4"
    }
   },
   "outputs": [],
   "source": [
    "def create_mnist(n_training = 5000):\n",
    "    explore(X_train, y_train)\n",
    "    X, _, y, _ = train_test_split(X_train, y_train, train_size=n_training, test_size=0)\n",
    "    def f(model):\n",
    "        trained = train(model, X, y)\n",
    "        y_pred = trained.predict(X_test)\n",
    "        print_prediction_stats(trained, y_test, y_pred)\n",
    "        return trained\n",
    "    return f\n",
    "\n",
    "MNIST = create_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a833377f-9eea-4ad1-942c-8f2c68f712e6"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Task 1: Run MNIST(MyModelInstance)\n",
    "#\n",
    "\n",
    "# TODO: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c3aaa5cf-e86d-4ff2-86fa-54b8876620cb"
    }
   },
   "source": [
    "## Deep Learning\n",
    "\n",
    "In this second part we are going to utilize deep learning strategies in order to improve accuracy! In particular, the neural network we will use is a convolutional neural network with 18 layers, taken from the brilliant [deep Learning turkey](https://medium.com/deep-learning-turkey/deep-learning-lab-episode-1-fashion-mnist-c7af60029836). Instead of training from scratch (because who has that kind of time), we are going to use pre-learned weights to get a network that already performs very well. \n",
    "\n",
    "In fact, this is a very common strategy: taking existing network architectures ([AlexNet](https://en.wikipedia.org/wiki/AlexNet), VGGNet, LeNet, ...) and training on top of pre-trained weights (e.g. [ImageNet data](http://www.image-net.org/)). This process is also called transfer learning and is quite useful for getting good results quickly. \n",
    "\n",
    "Instead of the turkey's network we could have adjusted the image size (filling up the background) to conform to AlexNet's (or similar) dimensions of 224x224. This is something that you can try on your own.\n",
    "\n",
    "\n",
    "\n",
    "### Task 2: Keep Training\n",
    "\n",
    "Once a network has been created, it's possible to add weights from previous training runs giving it a head start. Use Keras to load weights into the model and train for another epoch or two (depending on the time).  \n",
    "\n",
    "### Task 3: Gather Stats\n",
    "\n",
    "With the deep learning model, predict the classes of a few images from the test set and see how it performs. To do that, collect classification errors relative to the sample size!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # or cntk\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "79ae206c-eeee-4ca8-b9f5-9382b46adf9d"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.01), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (5, 5), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (5, 5), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cdd73dd5-bb37-442f-992c-abb6cf81dfa1"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Task 2: Keep training by loading the weights and running another training epoch or two.\n",
    "#\n",
    "\n",
    "# TODO: Insert code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "34e21520-93ff-4b77-9a54-ba864287a5d6"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Task 3: Gather prediction accuracy for a few (10?) items from the test data set\n",
    "#\n",
    "\n",
    "\n",
    "sample_size = 20\n",
    "error = 0\n",
    "\n",
    "# TODO: Insert code here\n",
    "\n",
    "print(\"Test accuracy: \", 1 - (error / sample_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d44bf531-0b4e-47dd-9d69-bcf1e4bedff6"
    }
   },
   "source": [
    "## APIs\n",
    "\n",
    "In a last attempt, let's try out some prebuilt services. In many cases they are a lot easier to use and produce usable results within minutes, making them ideal for prototypes as well as production cases. \n",
    "\n",
    "Microsoft's cognitive services contain various services around custom and prebuilt machine learning tasks, paid per call with a free tier. For this exercise, the free tier should work out fine - however production use cases better use a paid version :)\n",
    "\n",
    "The service we are using here is called [custom vision](https://customvision.ai) and provides a trainable image classification service complete with: \n",
    "\n",
    "- Model versioning\n",
    "- Rest API\n",
    "- UI for labelling and data management\n",
    "\n",
    "\n",
    "### Task 4: Data Wrangling\n",
    "\n",
    "A major task in any machine learning engagement is to get the data you need in the shape, mode, and size required. With this task you should fill in the function `make_img()` which is expected to create an image from a simple array of values. This image should be usable for the API!\n",
    "\n",
    "### Task 5: Test The API's Model\n",
    "\n",
    "Once trained, the model can deliver predictions! Find out how, implement it, and see how well it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping class numbers to names\n",
    "\n",
    "mapping = {\n",
    "    0: \"T-shirt/top\", \n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "training_key = \"\"\n",
    "project_id = \"\"\n",
    "prediction_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "638eaa8b-123c-47cb-8355-b0bc91a1c29e"
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "from azure.cognitiveservices.vision.customvision.prediction import prediction_endpoint\n",
    "from azure.cognitiveservices.vision.customvision.prediction.prediction_endpoint import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "045640f1-1f1c-4172-af34-c3becd59f797"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Task 4: Create a JPEG, PNG, or BMP to upload to custom vision.\n",
    "# \n",
    "\n",
    "def make_img(pd):\n",
    "    # TODO: return an actual image\n",
    "    return BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fba30b74-8b64-49ec-b99e-e960da1197dd"
    }
   },
   "outputs": [],
   "source": [
    "# Create API connection\n",
    "trainer = training_api.TrainingApi(training_key)\n",
    "\n",
    "# Creating tags twice will result in an error...\n",
    "tags = [trainer.create_tag(project_id, name) for key, name in sorted(mapping.items(), key=lambda i: i[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b77915c7-41e7-4c78-b697-8bd5dfe185ad"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a test set suitable for the free tier (5000 images take a long time to upload...)\n",
    "\n",
    "X, _, Y, _ = train_test_split(X_train, y_train, train_size = 100, test_size=0)\n",
    "\n",
    "for x, y in zip(X, Y):\n",
    "    img_data = make_img(x)\n",
    "    status = trainer.create_images_from_data(project_id, img_data, [ tags[np.where(y == 1)[0][0]].id ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "307b9486-4e7e-408c-9c0a-1c5b489078f1"
    }
   },
   "outputs": [],
   "source": [
    "# Start training and wait for it to finish.\n",
    "\n",
    "iteration = trainer.train_project(project_id)\n",
    "\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project_id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b46874dc-71e8-458a-9db6-a7d68bb6b4c7"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Task 5: Predict! Check the tutorials for how to create a prediction endpoint and use it to send images there\n",
    "#\n",
    "\n",
    "sample_size = 20\n",
    "errors = 0\n",
    "\n",
    "# TODO: insert code here :)\n",
    "\n",
    "print(\"Test accuracy: \", 1 - (errors / sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!\n",
    "\n",
    "That's it, there is way more to learn out there and this session should provide an overview over what's possible and a basic vocabulary. Check out these links to find out more about this entire space!\n",
    "\n",
    "- [Andrew Ng's ML basics course](https://www.coursera.org/learn/machine-learning)\n",
    "- [Deep Learning specialization](https://www.coursera.org/specializations/deep-learning)\n",
    "- [Understanding CNNs](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "- [Custom Vision SDK Tutorial](https://docs.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/python-tutorial)\n",
    "- [Keras Docs](https://keras.io/)\n",
    "- [Kaggle](https://kaggle.com)\n",
    "- [Deep Learning the Fashion MNIST](https://medium.com/deep-learning-turkey/deep-learning-lab-episode-1-fashion-mnist-c7af60029836)\n",
    "- [Fashion MNIST Benchmarks](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#)\n",
    "- [CNTK Tutorials](https://cntk.ai/pythondocs/tutorials.html)\n",
    "- [ML Tools on Azure](https://azure.microsoft.com/en-us/services/#ai-machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nbpresent": {
   "slides": {
    "0be37d33-b574-47f1-ba45-b13e88060351": {
     "id": "0be37d33-b574-47f1-ba45-b13e88060351",
     "prev": "acb069fb-3766-49ea-979f-6a7212d54b65",
     "regions": {
      "28e2b5c7-1f90-49ed-aa8c-a17c3ee77dd7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b77915c7-41e7-4c78-b697-8bd5dfe185ad",
        "part": "whole"
       },
       "id": "28e2b5c7-1f90-49ed-aa8c-a17c3ee77dd7"
      }
     }
    },
    "2365376d-cb66-4107-9f84-f21be017a4f3": {
     "id": "2365376d-cb66-4107-9f84-f21be017a4f3",
     "prev": "92ab60e1-65aa-4b5c-b051-39c105afe277",
     "regions": {
      "e14027fd-c077-4010-8d05-81ae45f911e2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b1c513fb-9e2b-4aa5-bb9a-2e79ab1f21c0",
        "part": "whole"
       },
       "id": "e14027fd-c077-4010-8d05-81ae45f911e2"
      }
     }
    },
    "2aa1ae0d-4176-4312-a159-3763caa82fbb": {
     "id": "2aa1ae0d-4176-4312-a159-3763caa82fbb",
     "prev": "fcabb04c-b487-4927-96c3-d48cbba2aa6a",
     "regions": {
      "a19c3721-42b4-4779-9b79-7212da0a0d57": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bb5283ac-ac7f-4982-af33-f06a944f1ad3",
        "part": "whole"
       },
       "id": "a19c3721-42b4-4779-9b79-7212da0a0d57"
      }
     }
    },
    "2c1289f7-ca30-4051-85f3-4c9f28c8cdc3": {
     "id": "2c1289f7-ca30-4051-85f3-4c9f28c8cdc3",
     "prev": "96580448-4db1-47a0-838d-4c16f61f288f",
     "regions": {
      "b574a93a-18a8-4a94-9058-6091b9afc9cd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3016fdb-e626-4c9d-badb-d14ef4027b42",
        "part": "whole"
       },
       "id": "b574a93a-18a8-4a94-9058-6091b9afc9cd"
      }
     }
    },
    "2f10d723-9a11-4539-8c04-9991772075f0": {
     "id": "2f10d723-9a11-4539-8c04-9991772075f0",
     "prev": "5c8fa775-66c0-4cba-b249-3874a5f47569",
     "regions": {
      "c6d2d156-3f12-4068-970e-c9dbe7a386a3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4fa0d0fb-566d-464a-8774-b1b36131f57e",
        "part": "whole"
       },
       "id": "c6d2d156-3f12-4068-970e-c9dbe7a386a3"
      }
     }
    },
    "5815c285-ab3f-4406-b93b-a583295c3d61": {
     "id": "5815c285-ab3f-4406-b93b-a583295c3d61",
     "prev": "bce54b2a-6256-4069-9624-f11a4bd12335",
     "regions": {
      "38188b22-a7bb-4308-bebb-56bca6d14381": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e02c22a3-f96c-4b1c-9fc8-ff04afeecd6e",
        "part": "whole"
       },
       "id": "38188b22-a7bb-4308-bebb-56bca6d14381"
      }
     }
    },
    "5c8fa775-66c0-4cba-b249-3874a5f47569": {
     "id": "5c8fa775-66c0-4cba-b249-3874a5f47569",
     "prev": "0be37d33-b574-47f1-ba45-b13e88060351",
     "regions": {
      "85fdb49e-140f-434b-9070-7d454f5300c7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "307b9486-4e7e-408c-9c0a-1c5b489078f1",
        "part": "whole"
       },
       "id": "85fdb49e-140f-434b-9070-7d454f5300c7"
      }
     }
    },
    "69061ed9-760b-43d8-9157-4443c1668b95": {
     "id": "69061ed9-760b-43d8-9157-4443c1668b95",
     "prev": "cb9103ba-165d-417e-9aaa-59620676f5bd",
     "regions": {
      "0fd7695f-7584-4399-acea-3ed8e3d6d674": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "045640f1-1f1c-4172-af34-c3becd59f797",
        "part": "whole"
       },
       "id": "0fd7695f-7584-4399-acea-3ed8e3d6d674"
      }
     }
    },
    "6db60f0b-1781-4711-99c6-befded93468c": {
     "id": "6db60f0b-1781-4711-99c6-befded93468c",
     "prev": "ea42c287-0300-4496-bc78-b1b44054e1c8",
     "regions": {
      "3a53efeb-b6ba-4840-a324-b04fc647f109": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a833377f-9eea-4ad1-942c-8f2c68f712e6",
        "part": "whole"
       },
       "id": "3a53efeb-b6ba-4840-a324-b04fc647f109"
      }
     }
    },
    "716699f0-37c4-4539-8345-0ff2687ac905": {
     "id": "716699f0-37c4-4539-8345-0ff2687ac905",
     "prev": "2f10d723-9a11-4539-8c04-9991772075f0",
     "regions": {
      "ea3d38f2-3d2f-4e3b-8c7d-904339fe67de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6cc3c11e-b663-4e82-ada8-1b6bd8991a26",
        "part": "whole"
       },
       "id": "ea3d38f2-3d2f-4e3b-8c7d-904339fe67de"
      }
     }
    },
    "7c4392d6-f195-4893-9f22-551e2d16cfd3": {
     "id": "7c4392d6-f195-4893-9f22-551e2d16cfd3",
     "prev": "b3c712ae-6eb6-47aa-bef6-8c18861f0d2f",
     "regions": {
      "c9ca8c1e-198c-46c9-93a8-1b5e91cbdd72": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "79ae206c-eeee-4ca8-b9f5-9382b46adf9d",
        "part": "whole"
       },
       "id": "c9ca8c1e-198c-46c9-93a8-1b5e91cbdd72"
      }
     }
    },
    "7cb9a248-cf6e-47e8-8f2a-2a84a4637663": {
     "id": "7cb9a248-cf6e-47e8-8f2a-2a84a4637663",
     "prev": "5815c285-ab3f-4406-b93b-a583295c3d61",
     "regions": {
      "f014594a-dfdf-47f1-8029-92bc88a352ce": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2d40da66-9ddc-4bc2-8979-0a47ef45fb4d",
        "part": "whole"
       },
       "id": "f014594a-dfdf-47f1-8029-92bc88a352ce"
      }
     }
    },
    "80a6e1cf-4dfd-4758-800e-481e217f4294": {
     "id": "80a6e1cf-4dfd-4758-800e-481e217f4294",
     "prev": "7cb9a248-cf6e-47e8-8f2a-2a84a4637663",
     "regions": {
      "43a13f25-727f-4c46-a317-16db439c2892": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "eb61b3a9-cea2-4214-8764-5f83c9fa2467",
        "part": "whole"
       },
       "id": "43a13f25-727f-4c46-a317-16db439c2892"
      }
     }
    },
    "92ab60e1-65aa-4b5c-b051-39c105afe277": {
     "id": "92ab60e1-65aa-4b5c-b051-39c105afe277",
     "prev": "80a6e1cf-4dfd-4758-800e-481e217f4294",
     "regions": {
      "d56ec6a8-2dda-4206-bb44-a299050b6470": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9398ad78-a0e9-40a7-9541-a25d08bf72ed",
        "part": "whole"
       },
       "id": "d56ec6a8-2dda-4206-bb44-a299050b6470"
      }
     }
    },
    "96580448-4db1-47a0-838d-4c16f61f288f": {
     "id": "96580448-4db1-47a0-838d-4c16f61f288f",
     "prev": null,
     "regions": {
      "c4d2f23d-eed8-4ab7-ac77-ff32ef495f08": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e8ac3b9-d70c-4a71-a13c-0c761d8a4665",
        "part": "whole"
       },
       "id": "c4d2f23d-eed8-4ab7-ac77-ff32ef495f08"
      }
     }
    },
    "97c3dd3d-aaaf-4ae7-a3b5-6fc8e18d4cc4": {
     "id": "97c3dd3d-aaaf-4ae7-a3b5-6fc8e18d4cc4",
     "prev": "afdd204b-5dae-4d28-9e0b-c49c561c113b",
     "regions": {
      "6634d276-7f56-4e6c-bb6d-708dc185ba55": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fba30b74-8b64-49ec-b99e-e960da1197dd",
        "part": "whole"
       },
       "id": "6634d276-7f56-4e6c-bb6d-708dc185ba55"
      }
     }
    },
    "acb069fb-3766-49ea-979f-6a7212d54b65": {
     "id": "acb069fb-3766-49ea-979f-6a7212d54b65",
     "prev": "97c3dd3d-aaaf-4ae7-a3b5-6fc8e18d4cc4",
     "regions": {
      "2720cb18-ad75-4d31-b66d-1a25e6701360": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bfb47c20-60c0-49a0-99ed-af3739ca8762",
        "part": "whole"
       },
       "id": "2720cb18-ad75-4d31-b66d-1a25e6701360"
      }
     }
    },
    "afdd204b-5dae-4d28-9e0b-c49c561c113b": {
     "id": "afdd204b-5dae-4d28-9e0b-c49c561c113b",
     "prev": "69061ed9-760b-43d8-9157-4443c1668b95",
     "regions": {
      "e0ac2320-3076-4d3a-95df-65f8ae908c44": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3ae6cda9-5815-4cc2-b269-4c3541e356d6",
        "part": "whole"
       },
       "id": "e0ac2320-3076-4d3a-95df-65f8ae908c44"
      }
     }
    },
    "b3c712ae-6eb6-47aa-bef6-8c18861f0d2f": {
     "id": "b3c712ae-6eb6-47aa-bef6-8c18861f0d2f",
     "prev": "6db60f0b-1781-4711-99c6-befded93468c",
     "regions": {
      "e8e140ae-eda7-4a78-93ea-f8b121238c20": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c3aaa5cf-e86d-4ff2-86fa-54b8876620cb",
        "part": "whole"
       },
       "id": "e8e140ae-eda7-4a78-93ea-f8b121238c20"
      }
     }
    },
    "bce54b2a-6256-4069-9624-f11a4bd12335": {
     "id": "bce54b2a-6256-4069-9624-f11a4bd12335",
     "prev": "2aa1ae0d-4176-4312-a159-3763caa82fbb",
     "regions": {
      "758f5525-5ed3-4226-b9c2-466f094c4879": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "468fa019-0a34-4ca8-be40-b0de3cb10a2a",
        "part": "whole"
       },
       "id": "758f5525-5ed3-4226-b9c2-466f094c4879"
      }
     }
    },
    "cb9103ba-165d-417e-9aaa-59620676f5bd": {
     "id": "cb9103ba-165d-417e-9aaa-59620676f5bd",
     "prev": "f24d2b59-6376-4de6-8bbd-cee9dfa8ab41",
     "regions": {
      "66bd2fa3-2fb8-4db5-9e9b-a38fc29823e3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "638eaa8b-123c-47cb-8355-b0bc91a1c29e",
        "part": "whole"
       },
       "id": "66bd2fa3-2fb8-4db5-9e9b-a38fc29823e3"
      }
     }
    },
    "ccd11861-c269-4b59-86f4-5ce8b69a82df": {
     "id": "ccd11861-c269-4b59-86f4-5ce8b69a82df",
     "prev": "7c4392d6-f195-4893-9f22-551e2d16cfd3",
     "regions": {
      "a6262b5e-3e62-4fe4-84ef-39818f046dc1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cdd73dd5-bb37-442f-992c-abb6cf81dfa1",
        "part": "whole"
       },
       "id": "a6262b5e-3e62-4fe4-84ef-39818f046dc1"
      }
     }
    },
    "dad4a1a8-b156-4028-8084-323625610b24": {
     "id": "dad4a1a8-b156-4028-8084-323625610b24",
     "prev": "716699f0-37c4-4539-8345-0ff2687ac905",
     "regions": {
      "fb5782fa-8d30-490e-b0b0-431f1a2dc6ab": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b46874dc-71e8-458a-9db6-a7d68bb6b4c7",
        "part": "whole"
       },
       "id": "fb5782fa-8d30-490e-b0b0-431f1a2dc6ab"
      }
     }
    },
    "dc453b61-29d1-4430-82a5-0342d3d3ce1d": {
     "id": "dc453b61-29d1-4430-82a5-0342d3d3ce1d",
     "prev": "dad4a1a8-b156-4028-8084-323625610b24",
     "regions": {
      "57d2bc68-ef49-4e3e-95f9-b70cbba6232a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2dd0f0a2-5224-4975-a5a8-82ba5430fa79",
        "part": "whole"
       },
       "id": "57d2bc68-ef49-4e3e-95f9-b70cbba6232a"
      }
     }
    },
    "ea42c287-0300-4496-bc78-b1b44054e1c8": {
     "id": "ea42c287-0300-4496-bc78-b1b44054e1c8",
     "prev": "2365376d-cb66-4107-9f84-f21be017a4f3",
     "regions": {
      "3bb78ab5-47f7-4c08-a864-c7365a3f2271": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3f3bf255-c20c-4aa5-9363-e5ca2a57b7e4",
        "part": "whole"
       },
       "id": "3bb78ab5-47f7-4c08-a864-c7365a3f2271"
      }
     }
    },
    "f24d2b59-6376-4de6-8bbd-cee9dfa8ab41": {
     "id": "f24d2b59-6376-4de6-8bbd-cee9dfa8ab41",
     "prev": "f3be65ae-68cd-497e-962d-2e134190dbaf",
     "regions": {
      "3924f060-84f7-4569-adda-ca9a7166e21d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d44bf531-0b4e-47dd-9d69-bcf1e4bedff6",
        "part": "whole"
       },
       "id": "3924f060-84f7-4569-adda-ca9a7166e21d"
      }
     }
    },
    "f3be65ae-68cd-497e-962d-2e134190dbaf": {
     "id": "f3be65ae-68cd-497e-962d-2e134190dbaf",
     "prev": "ccd11861-c269-4b59-86f4-5ce8b69a82df",
     "regions": {
      "3d5e76f4-0769-4365-a79a-d70685f1dbd8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "34e21520-93ff-4b77-9a54-ba864287a5d6",
        "part": "whole"
       },
       "id": "3d5e76f4-0769-4365-a79a-d70685f1dbd8"
      }
     }
    },
    "fcabb04c-b487-4927-96c3-d48cbba2aa6a": {
     "id": "fcabb04c-b487-4927-96c3-d48cbba2aa6a",
     "prev": "2c1289f7-ca30-4051-85f3-4c9f28c8cdc3",
     "regions": {
      "14f7c226-cac9-48bf-a269-207e4b9d479f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "444f1646-a6c9-4527-955b-185347192e5c",
        "part": "whole"
       },
       "id": "14f7c226-cac9-48bf-a269-207e4b9d479f"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
